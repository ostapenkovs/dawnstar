{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dawnstar, a patent expiration workflow.\n",
    "#\n",
    "# Programmatically find projected expiration dates \n",
    "# and other assumed status details for compound patents.\n",
    "#\n",
    "#   Requiring Python == 3.11.\n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import bs4\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import random\n",
    "\n",
    "import psycopg2\n",
    "from secret import db_info\n",
    "\n",
    "DATA_FOLDER = './compound_data'\n",
    "HEADERS = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'}\n",
    "\n",
    "def get_compounds(infile: str, canonical: bool) -> list:\n",
    "    \"\"\"Process user input-file and return compound SMILES after sanitizing.\"\"\"\n",
    "    compounds = []\n",
    "    if infile.split('.')[-1] == 'sdf':\n",
    "        all_mols = Chem.SDMolSupplier(infile)\n",
    "    else:\n",
    "        with open(infile, 'r') as f:\n",
    "            all_mols = [Chem.MolFromSmiles(line.strip()) for line in f]\n",
    "    for mol in all_mols:\n",
    "        if mol:\n",
    "            if canonical:\n",
    "                smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "            else:\n",
    "                smi = Chem.MolToSmiles(mol, isomericSmiles=True, kekuleSmiles=True)\n",
    "            if smi:\n",
    "                compounds.append(smi)\n",
    "    return compounds\n",
    "\n",
    "def validate_date(date: str) -> bool:\n",
    "    \"\"\"Validate potential before and after date cutoffs.\n",
    "    Want date to be before NOW and after Jan. 1st, 1970.\"\"\"\n",
    "    try:\n",
    "        if len(date) == 8:\n",
    "            yr, mo, dy = int(date[0:4]), int(date[4:6]), int(date[6:8])\n",
    "            date = datetime(year=yr, month=mo, day=dy)\n",
    "            if date >= datetime(year=1970, month=1, day=1) and date < datetime.now():\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return False\n",
    "\n",
    "def safe_select(event: bs4.element.Tag, item: str) -> str | int:\n",
    "    \"\"\"Process HTML tags in patent timeline to ensure accurate scraping.\"\"\"\n",
    "    try:\n",
    "        val = event.select_one(item).text.strip()\n",
    "        val = None if not val else val\n",
    "    except:\n",
    "        val = None\n",
    "    return val\n",
    "\n",
    "def build_query(compound: str, is_smiles: bool, search_type: str, base_filters: bool, after: None | str, before: None | str) -> tuple:\n",
    "    \"\"\"Build two query URLs for a given compound, one for search and one for XHR download.\n",
    "    Returns tuple of length two with each URL.\"\"\"\n",
    "    if is_smiles:\n",
    "        to_replace = {'%': r'%25', '+': r'%2b', '=': r'%3d', '/': r'%2f', '#': r'%23'}\n",
    "        for ch in to_replace.keys():\n",
    "            compound = compound.replace(ch, to_replace[ch])\n",
    "    \n",
    "    eq1 = r'%3d'\n",
    "    sim_sub = ''\n",
    "    if search_type == 'substructure':\n",
    "        sim_sub = f'SSS{eq1}'\n",
    "    elif search_type == 'similarity':\n",
    "        sim_sub = '~'\n",
    "    \n",
    "    base_filter = ''\n",
    "    if base_filters:\n",
    "        base_filter = '&country=US&language=ENGLISH&type=PATENT'\n",
    "    \n",
    "    after_filter, before_filter = '', ''\n",
    "    if after:\n",
    "        after_filter = f'&after=priority:{after}'\n",
    "    if before:\n",
    "        before_filter = f'&before=priority:{before}'\n",
    "    \n",
    "    query = f'q=CL{eq1}{sim_sub}({compound}){base_filter}{after_filter}{before_filter}'\n",
    "\n",
    "    search_url = 'https://patents.google.com/?' + query\n",
    "\n",
    "    eq2, amp, col, pct3d, b1, b2, pct2b = r'%3D', r'%26', r'%3A', r'%253d', r'%5B', r'%5D', r'%252b'\n",
    "    query = query.replace(eq1, pct3d).replace('=', eq2).replace('&', amp).replace(':', col).replace('[', b1).replace(']', b2).replace(r'%2b', pct2b)\n",
    "    download_url = f'https://patents.google.com/xhr/query?url=' + query + '&exp=&download=true'\n",
    "\n",
    "    return search_url, download_url\n",
    "\n",
    "def parse_timeline(page_text: str) -> tuple:\n",
    "    \"\"\"Process webpage text of a single patent for a given compound.\n",
    "    Extract timeline events, in particular status and expiration.\"\"\"\n",
    "    title = date = status = status_detail = None\n",
    "    soup = bs4.BeautifulSoup(page_text, 'html.parser')\n",
    "    title, events = soup.find('title').text.split()[0], soup.find_all('dd', {'itemprop': \"events\"})\n",
    "    soup = None\n",
    "    for event in events:\n",
    "        e_type = safe_select(event, 'span[itemprop=\"type\"]')\n",
    "        if e_type is not None and e_type == 'legal-status':\n",
    "            e_title = safe_select(event, 'span[itemprop=\"title\"]')\n",
    "            e_date = safe_select(event, 'time[itemprop=\"date\"]')\n",
    "            if e_date is not None and e_date == 'Status':\n",
    "                status = e_title\n",
    "            elif e_date is not None:\n",
    "                status_detail = e_title\n",
    "                date = e_date\n",
    "    return title, date, status, status_detail\n",
    "\n",
    "async def get_url_async(session: aiohttp.ClientSession, url: str, headers: dict) -> str:\n",
    "    \"\"\"Makes async request to get single patent webpage text.\n",
    "    Raises error if response is not 200.\"\"\"\n",
    "    async with session.get(url=url, headers=headers) as response:\n",
    "        response.raise_for_status()\n",
    "        return await response.text()\n",
    "\n",
    "async def get_timeline_async(session: aiohttp.ClientSession, url: str, headers: dict) -> tuple | None:\n",
    "    \"\"\"Async wrapper for parse_timeline function.\"\"\"\n",
    "    page_text = await get_url_async(session=session, url=url, headers=headers)\n",
    "    title, date, status, status_detail = parse_timeline(page_text=page_text)\n",
    "    if title and date and (status or status_detail):\n",
    "        return (title, (date, status, status_detail))\n",
    "    return None\n",
    "\n",
    "async def get_all_async(urls: list, headers: dict) -> list:\n",
    "    \"\"\"Collect information for all patents in async fashion.\"\"\"\n",
    "    l = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i, url in enumerate(urls):\n",
    "            l.append(get_timeline_async(session=session, url=url, headers=headers))\n",
    "            if i % 5 == 0 and i > 0:\n",
    "                print(f'Processed URL {i}.')\n",
    "        return await asyncio.gather(*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = './compound_data/metformin.txt'\n",
    "is_smiles = True\n",
    "search_type = 'exact' #'similarity', 'substructure'\n",
    "after = None\n",
    "before = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds = get_compounds(infile=infile, canonical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CN(C)C(=N)N=C(N)N'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = compounds[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_info = {\n",
    "    'user': 'vpolyakov', \n",
    "    'password': 'Pi3dato1', \n",
    "    'dbname': 'waffles', \n",
    "    'host': 'hyperion', \n",
    "    'port': 5432\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(**db_info)\n",
    "curs = conn.cursor()\n",
    "curs.execute('set search_path to sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4808,)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curs.execute('select count(id) from cdb_compound')\n",
    "curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7404489,)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curs.execute('select count(id) from compound')\n",
    "curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'CN(C)C(=N)N=C(N)N'\n",
    "curs.execute('select p.num \\\n",
    "             from compound c, patent p, field_freq f \\\n",
    "             where c.id = f.compound_id and p.id = f.patent_id and f.field_id = 2 \\\n",
    "             and c.smiles @= %s', (s, ))\n",
    "\n",
    "r = [x[0] for x in curs.fetchall()]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US20150050241A1', 'US20150111731A1', 'US20150072859A1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curs.execute('select p.num \\\n",
    "             from compound c, patent p, field_freq f \\\n",
    "             where c.id = f.compound_id and p.id = f.patent_id and f.field_id = 2 \\\n",
    "             and c.smiles@>%s', (s, ))\n",
    "\n",
    "r = [x[0] for x in curs.fetchall()]\n",
    "r[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.40\n",
    "m = Chem.MolFromSmiles(s)\n",
    "b_mfp = DataStructs.BitVectToBinaryText( AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=1024) )\n",
    "\n",
    "curs.execute(f'set rdkit.tanimoto_threshold={thresh}')\n",
    "curs.execute('select p.num \\\n",
    "             from compound c, patent p, field_freq f \\\n",
    "             where c.id = f.compound_id and p.id = f.patent_id and f.field_id = 2 \\\n",
    "             and c.mfp%%bfp_from_binary_text(%s)', (b_mfp, ))\n",
    "\n",
    "r = [x[0] for x in curs.fetchall()]\n",
    "r[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using USPTO PEDS API to find patent information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USPTO PEDS API\n",
    "# url = 'https://ped.uspto.gov/api/queries'\n",
    "# headers = {\n",
    "#     'Content-Type': 'application/json',\n",
    "#     'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \\\n",
    "#         AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n",
    "#     }\n",
    "# solr_query = {\n",
    "#     'df': 'appEarlyPubNumber',\n",
    "#     'mm': '100%',\n",
    "#     'fl': '*',\n",
    "#     'facet': 'false',\n",
    "#     }\n",
    "\n",
    "# found = []\n",
    "# cols = ['appEarlyPubNumber', 'patentNumber', 'appStatus', 'patentTitle', 'patentIssueDate']\n",
    "# with requests.session() as s:\n",
    "#     for patent in patents:\n",
    "#         for status in ['Patented Case', 'Abandoned']:\n",
    "#             solr_query['searchText'] = 'appEarlyPubNumber:' + patent\n",
    "#             solr_query['fq'] = ['appStatus:\\\"' + status + '\\\"']\n",
    "\n",
    "#             response = s.post(url, json=solr_query, headers=headers)\n",
    "#             if response:\n",
    "#                 d = response.json()\n",
    "                \n",
    "#                 res_d = d['queryResults']['searchResponse']['response']\n",
    "#                 if res_d['numFound'] >= 1:\n",
    "#                     for doc in res_d['docs']:\n",
    "#                         found.append([doc[x] for x in cols])\n",
    "\n",
    "# pd.DataFrame(found, columns=cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dawnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59f4bb288cd16d6415abd8fbad011797fb186218e02b0efc44690046d2ab96a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
